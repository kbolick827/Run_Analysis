download.file(dataset_url, "diet_data.zip")
unzip("diet_data.zip", exdir = "diet_data")
list.files("diet_data")
ï¿¼andy <- read.csv("diet_data/Andy.csv")
and <- read.csv("diet_data/Andy.csv")
andy <- read.csv("diet_data/Andy.csv")
head(andy)
length(andy$Day)
length(andy$Age)
crazy <- function() {
x <- 42
x <<- 3.14
print(x)
}
crazy()
crazy(x)
crazy()
crazy()
crazy()
## This pair of functions caches the inverse of a matrix
## This function creates a special "matrix" object that can cache its inverse.
makeCacheMatrix <- function(x = matrix()) {
inv <- NULL
set <- function(y) {
x <<- y
inv <<- NULL
}
get <- function() x
setinverse <- function(inverse) inv <<- inverse
getinverse <- function() inv
list(set=set, get=get, setinverse=setinverse, getinverse=getinverse)
}
## This function computes the inverse of the special "matrix" returned by makeCacheMatrix.
## If the inverse has already been calculated (and the matrix has not changed),
## then the cachesolve retrieves the inverse from the cache.
## CacheSolve assumes that the matrix supplied is always invertible
## Returns a matrix that is the inverse of 'x'
cacheSolve <- function(x, ...) {
inv <- x$getinverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data)
x$setinverse(inv)
inv
}
x <-rbind(c(1, -1/4), c(-1/4,1))
m <- makeCacheMatrix(x)
m$get()
cacheSolve(m)
cacheSolve(m)
library(swirl)
swirl()
swirl()
head(flags)
dim(flags)
class(flags)
cls_list <- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
cls_list <- sapply(flags, class)
cls_vect <- sapply(flags, class)
class(cls_vect)
set.seed(1)
rpois (5,2)
install("xlsx")
install.packages("xlsx")
complete <- function(directory, id = 1:332) {
install.packages("RMysql")
install.packages("RMySQL")
ucscDb <- dbConnect(MySQL(),user="genome",
host="genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb,"show databases;"); dbDisconnect(ucscDb);
library("RMySQL")
ucscDb <- dbConnect(MySQL(),user="genome",
host="genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb,"show databases;"); dbDisconnect(ucscDb);
result
hg19 <- dbConnect(MySQL(),user="genome", db="hg19",
host="genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
alltables[1:5]
allTables[1:5]
install.packages("jsonlite")
library(httr)oauth_endpoints("github")myapp <- oauth_app("github", "a10ed45403ee0c2a83cd", " 92b4b448edc4d5036cff4d7ae89990aaeacf2bbb")github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)req <- GET("https://api.github.com/rate_limit", config(token = github_token))stop_for_status(req)content(req)BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
library(httr)oauth_endpoints("github")myapp <- oauth_app("github", "a10ed45403ee0c2a83cd", "92b4b448edc4d5036cff4d7ae89990aaeacf2bbb")github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)req <- GET("https://api.github.com/rate_limit", config(token = github_token))stop_for_status(req)content(req)BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
library(httr)oauth_endpoints("github")myapp <- oauth_app("github", "a10ed45403ee0c2a83cd", "92b4b448edc4d5036cff4d7ae89990aaeacf2bbb")github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)req <- GET("https://api.github.com/rate_limit", config(token = github_token))stop_for_status(req)content(req)BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "a10ed45403ee0c2a83cd", "92b4b448edc4d5036cff4d7ae89990aaeacf2bbb")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages("httpuv")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(httr)oauth_endpoints("github")myapp <- oauth_app("github", "a10ed45403ee0c2a83cd", "92b4b448edc4d5036cff4d7ae89990aaeacf2bbb")github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)req <- GET("https://api.github.com/rate_limit", config(token = github_token))stop_for_status(req)content(req)BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
req <- GET("https://api.github.com/rate_limit", config(token = github_token))
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "a10ed45403ee0c2a83cd", "92b4b448edc4d5036cff4d7ae89990aaeacf2bbb")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(data.table)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl, destfile = "Dataset.zip", method="curl")
date_downloaded <- date()
date_downloaded
unzip("Dataset.zip")
testData <- read.table("./UCI HAR Dataset/test/X_test.txt",header=FALSE)
testData_act <- read.table("./UCI HAR Dataset/test/y_test.txt",header=FALSE)
testData_sub <- read.table("./UCI HAR Dataset/test/subject_test.txt",header=FALSE)
trainData <- read.table("./UCI HAR Dataset/train/X_train.txt",header=FALSE)
trainData_act <- read.table("./UCI HAR Dataset/train/y_train.txt",header=FALSE)
trainData_sub <- read.table("./UCI HAR Dataset/train/subject_train.txt",header=FALSE)
# 3. Uses descriptive activity names to name the activities in the data set
activities <- read.table("./UCI HAR Dataset/activity_labels.txt",header=FALSE,colClasses="character")
testData_act$V1 <- factor(testData_act$V1,levels=activities$V1,labels=activities$V2)
trainData_act$V1 <- factor(trainData_act$V1,levels=activities$V1,labels=activities$V2)
# 4. Appropriately labels the data set with descriptive activity names
features <- read.table("./UCI HAR Dataset/features.txt",header=FALSE,colClasses="character")
colnames(testData) <- features$V2
colnames(trainData) <- features$V2
colnames(testData_act) <- c("Activity")
colnames(trainData_act) <- c("Activity")
colnames(testData_sub) <- c("Subject")
colnames(trainData_sub) <- c("Subject")
# 1. merge test and training sets into one data set, including the activities
testData <- cbind(testData,testData_act)
testData <- cbind(testData,testData_sub)
trainData <- cbind(trainData,trainData_act)
trainData <- cbind(trainData,trainData_sub)
Merged_Data <- rbind(testData,trainData)
# 2. extract only the measurements on the mean and standard deviation for each measurement
Data_mean <- sapply(Merged_Data,mean,na.rm=TRUE)
Data_sd <- sapply(Merged_Data,sd,na.rm=TRUE)
# 5. Creates a second, independent tidy data set with the average of each variable for each activity and each subject.
DT <- data.table(Merged_Data)
tidy <- DT[,lapply(.SD,mean),by="Subject,Activity"]
sort_tidy <- tidy[order(Subject, Activity),]
write.table(sort_tidy,file="tidy.csv",sep=",",row.names = FALSE)
print("Finished processing. Tidy dataset is written to tidy.csv")
#### This code is for Plot 1 of project 1 for the Coursera course "Exploratory Data Analysis"
#### Date: June 8, 2014
#### Author: Mark Dakkak
######### Set working directory #########
setwd("/Users/sommpd10/datasciencecoursera/Exploratory-Data-Analysis")
######### Load data.table library #########
library(data.table)
######### Read in zip file #########
url <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip"
file <- "household_power_consumption"
download.file(url, file, method = "curl")
unzip(file, exdir = "/Users/sommpd10/datasciencecoursera/Exploratory-Data-Analysis")
# Creates the "household_power_consumption.txt" file!
data <- fread("household_power_consumption.txt")
######### Clean data #########
class(data$Date)
class(data$Time)
# Data and time variables are characters
# Change the format of Date variable
data$Date <- as.Date(data$Date, format="%d/%m/%Y")
class(data$Date)
# Subset the data for the two dates of interest
data_subset <- data[data$Date=="2007-02-01" | data$Date=="2007-02-02"]
# Convert data subset to a data frame
class(data_subset)
data_subset <- data.frame(data_subset)
# Convert columns to numeric
for(i in c(3:9)) {data_subset[,i] <- as.numeric(as.character(data_subset[,i]))}
# Create Date_Time variable
data_subset$Date_Time <- paste(data_subset$Date, data_subset$Time)
# Convert Date_Time variable to proper format
data_subset$Date_Time <- strptime(data_subset$Date_Time, format="%Y-%m-%d %H:%M:%S")
class(data_subset$Date_Time)
######### Plot 1 #########
png(filename = "plot1.png", width = 480, height = 480, units = "px", bg = "white")
par(mar = c(6, 6, 5, 4))
hist(data_subset$Global_active_power, col = "red", main = "Global Active Power", xlab = "Global Active Power(kilowatts)")
dev.off()
# Exploratory Data Analysis
# Project 2
# Clean upworkspace
rm(list=ls())
library("plyr")
# Load data
NEI <- readRDS("~/Downloads/exdata-data-NEI_data/summarySCC_PM25.rds")
SCC <- readRDS("~/Downloads/exdata-data-NEI_data/Source_Classification_Code.rds")
data<-transform(NEI,year=factor(year))
#Plot Data
plotdata<-ddply(data,.(year),summarize,sum=sum(Emissions))
png("plot1.png")
plot(plotdata$year,plotdata$sum,type="n",xlab="year",ylab="total PM2.5 Emission",boxwex=0.05)
lines(plotdata$year,plotdata$sum)
dev.off()
# uses data from the UC Irvine Machine Learning Repository found at http://archive.ics.uci.edu/ml/
# only data from 2007-02-01 and 2007-02-02 is used for the analysis
# "?" is the NA character in the data set so it is handled as such
data <- read.table(file = "household_power_consumption.txt", sep = ";",na.strings= "?")
dt <-  colnames(read.table("household_power_consumption.txt", sep = ";",nrow = 1, header = TRUE))
data = subset(data,as.Date(data$Timestamp) >= "2007-02-01" & as.Date(data$Timestamp) < "2007-02-03")
# assigns column names
names(data) <- dt
str(data)
date_time <- paste(data$Date,data$Time)
day_week <- strptime(date_time, format ='%d/%m/%Y %H:%M:%S')
str(day_week)
# creates plot1.png with a width of 480 pixels and a height of 480 pixels
png("plot1.png",width =480,height=480)
hist(data$Global_active_power,col="red", main ="Global Active Power",xlab="Global Active Power (kilowatts)")
dev.off()
# uses data from the UC Irvine Machine Learning Repository found at http://archive.ics.uci.edu/ml/
# only data from 2007-02-01 and 2007-02-02 is used for the analysis
# "?" is the NA character in the data set so it is handled as such
data <- read.table(file = "household_power_consumption.txt", sep = ";",na.strings= "?")
dt <-  colnames(read.table("household_power_consumption.txt", sep = ";",nrow = 1, header = TRUE))
sub_data = subset(data,as.Date(data$Timestamp) >= "2007-02-01" & as.Date(data$Timestamp) < "2007-02-03")
# assigns column names
names(sub_data) <- dt
str(sub_data)
date_time <- paste(sub_data$Date,data$Time)
day_week <- strptime(date_time, format ='%d/%m/%Y %H:%M:%S')
str(day_week)
# creates plot1.png with a width of 480 pixels and a height of 480 pixels
png("plot1.png",width =480,height=480)
hist(data$Global_active_power,col="red", main ="Global Active Power",xlab="Global Active Power (kilowatts)")
dev.off()
# uses data from the UC Irvine Machine Learning Repository found at http://archive.ics.uci.edu/ml/
# only data from 2007-02-01 and 2007-02-02 is used for the analysis
# "?" is the NA character in the data set so it is handled as such
data <- read.table(file = "household_power_consumption.txt", sep = ";",na.strings= "?")
dt <-  colnames(read.table("household_power_consumption.txt", sep = ";",nrow = 1, header = TRUE))
sub_data = subset(data,as.Date(data$Timestamp) >= "2007-02-01" & as.Date(data$Timestamp) < "2007-02-03")
# assigns column names
names(sub_data) <- dt
str(sub_data)
date_time <- paste(sub_data$Date,data$Time)
day_week <- strptime(date_time, format ='%d/%m/%Y %H:%M:%S')
str(day_week)
# creates plot1.png with a width of 480 pixels and a height of 480 pixels
png("plot1.png",width =480,height=480)
hist(sub_data$Global_active_power,col="red", main ="Global Active Power",xlab="Global Active Power (kilowatts)")
dev.off()
sub_data = subset(data,as.Date(data$Timestamp) >= "2007-02-01" & as.Date(data$Timestamp) < "2007-02-03")
# uses data from the UC Irvine Machine Learning Repository found at http://archive.ics.uci.edu/ml/
# only data from 2007-02-01 and 2007-02-02 is used for the analysis
# "?" is the NA character in the data set so it is handled as such
data <- read.table(file = "household_power_consumption.txt", sep = ";",na.strings= "?")
dt <-  colnames(read.table("household_power_consumption.txt", sep = ";",nrow = 1, header = TRUE))
# Combine the date and time columns into one timestapm
data$Timestamp <- strptime(paste(data$Date,data$Time),
format="%d/%m/%Y %H:%M:%S")
# Drop the now-unnecessary date and time cols
data$Date=NULL
data$Time=NULL
sub_data = subset(data,as.Date(data$Timestamp) >= "2007-02-01" & as.Date(data$Timestamp) < "2007-02-03")
# assigns column names
names(sub_data) <- dt
str(sub_data)
date_time <- paste(sub_data$Date,data$Time)
day_week <- strptime(date_time, format ='%d/%m/%Y %H:%M:%S')
str(day_week)
# creates plot1.png with a width of 480 pixels and a height of 480 pixels
png("plot1.png",width =480,height=480)
hist(sub_data$Global_active_power,col="red", main ="Global Active Power",xlab="Global Active Power (kilowatts)")
dev.off()
# uses data from the UC Irvine Machine Learning Repository found at http://archive.ics.uci.edu/ml/
# only data from 2007-02-01 and 2007-02-02 is used for the analysis
data <- read.table(file = "household_power_consumption.txt", sep = ";", skip = 66637,nrows = 2880,na.strings= "?")
# Combine the date and time columns into one timestapm
data$Timestamp <- strptime(paste(data$Date,data$Time),
format="%d/%m/%Y %H:%M:%S")
# Drop the now-unnecessary date and time cols
data$Date=NULL
data$Time=NULL
# Subset the data to only look at desired time span
# Here we'll be working with data from 2007-02-01 to 2007-02-02.
sub_data = subset(data,as.Date(data$Timestamp) >= "2007-02-01"
& as.Date(data$Timestamp) < "2007-02-03")
# creates plot1.png with a width of 480 pixels and a height of 480 pixels
png("plot1.png",width =480,height=480)
hist(sub_data$Global_active_power,col="red", main ="Global Active Power",xlab="Global Active Power (kilowatts)")
dev.off()
# uses data from the UC Irvine Machine Learning Repository found at http://archive.ics.uci.edu/ml/
# only data from 2007-02-01 and 2007-02-02 is used for the analysis
data <- read.table(file = "household_power_consumption.txt", sep = ";", skip = 66637,nrows = 2880,na.strings= "?")
# Combine the date and time columns into one timestapm
data$Timestamp <- strptime(paste(data$Date,data$Time),
format="%d/%m/%Y %H:%M:%S")
# Drop the now-unnecessary date and time cols
data$Date=NULL
data$Time=NULL
# Subset the data to only look at desired time span
# Here we'll be working with data from 2007-02-01 to 2007-02-02.
sub_data = subset(data,as.Date(data$Timestamp) >= "2007-02-01"
& as.Date(data$Timestamp) < "2007-02-03")
# creates plot1.png with a width of 480 pixels and a height of 480 pixels
png("plot1.png",width =480,height=480)
hist(sub_data$Global_active_power,col="red", main ="Global Active Power",xlab="Global Active Power (kilowatts)")
dev.off()
# uses data from the UC Irvine Machine Learning Repository found at http://archive.ics.uci.edu/ml/
# only data from 2007-02-01 and 2007-02-02 is used for the analysis
data <- read.table(file = "household_power_consumption.txt", sep = ";",na.strings= "?")
# Combine the date and time columns into one timestapm
data$Timestamp <- strptime(paste(data$Date,data$Time),
format="%d/%m/%Y %H:%M:%S")
# Drop the now-unnecessary date and time cols
data$Date=NULL
data$Time=NULL
# Subset the data to only look at desired time span
# Here we'll be working with data from 2007-02-01 to 2007-02-02.
sub_data = subset(data,as.Date(data$Timestamp) >= "2007-02-01"
& as.Date(data$Timestamp) < "2007-02-03")
# creates plot1.png with a width of 480 pixels and a height of 480 pixels
png("plot1.png",width =480,height=480)
hist(sub_data$Global_active_power,col="red", main ="Global Active Power",xlab="Global Active Power (kilowatts)")
dev.off()
# uses data from the UC Irvine Machine Learning Repository found at http://archive.ics.uci.edu/ml/
# only data from 2007-02-01 and 2007-02-02 is used for the analysis
data <- read.table(file = "household_power_consumption.txt", sep = ";",na.strings= "?")
# Combine the date and time columns into one timestapm
data$Timestamp <- strptime(paste(data$Date,data$Time),
format="%d/%m/%Y %H:%M:%S")
# Drop the now-unnecessary date and time cols
data$Date=NULL
data$Time=NULL
# Subset the data to only look at desired time span
# Here we'll be working with data from 2007-02-01 to 2007-02-02.
sub_data = subset(data,as.Date(data$Timestamp) >= "2007-02-01"
& as.Date(data$Timestamp) < "2007-02-03")
# creates plot1.png with a width of 480 pixels and a height of 480 pixels
# Plot the histogram
hist(sub_data$Global_active_power,
col="red",
main="Global Active Power",
xlab="Global Active Power (kilowatts)",
ylab="Frequency")
# Save the figure
dev.off()
# uses data from the UC Irvine Machine Learning Repository found at http://archive.ics.uci.edu/ml/
# only data from 2007-02-01 and 2007-02-02 is used for the analysis
data <- read.table(file = "household_power_consumption.txt", sep = ";",na.strings= "?")
# Combine the date and time columns into one timestapm
data$Timestamp <- strptime(paste(data$Date,data$Time),
format="%d/%m/%Y %H:%M:%S")
# Drop the now-unnecessary date and time cols
data$Date=NULL
data$Time=NULL
# Subset the data to only look at desired time span
# Here we'll be working with data from 2007-02-01 to 2007-02-02.
sub_data = subset(data,as.Date(data$Timestamp) >= "2007-02-01"
& as.Date(data$Timestamp) < "2007-02-03")
# Start the png device
png(filename="plot1.png", height=480, width=480, bg="transparent")
# creates plot1.png with a width of 480 pixels and a height of 480 pixels
# Plot the histogram
hist(sub_data$Global_active_power,
col="red",
main="Global Active Power",
xlab="Global Active Power (kilowatts)",
ylab="Frequency")
# Save the figure
dev.off()
# uses data from the UC Irvine Machine Learning Repository found at http://archive.ics.uci.edu/ml/
# only data from 2007-02-01 and 2007-02-02 is used for the analysis
data <- read.table(file = "household_power_consumption.txt", sep = ";",na.strings= "?")
# Combine the date and time columns into one timestapm
data$Timestamp <- strptime(paste(data$Date,data$Time),
format="%d/%m/%Y %H:%M:%S")
# Drop the now-unnecessary date and time cols
data$Date=NULL
data$Time=NULL
# Subset the data to only look at desired time span
# Here we'll be working with data from 2007-02-01 to 2007-02-02.
sub_data = subset(data,as.Date(data$Timestamp) >= "2007-02-01"
& as.Date(data$Timestamp) < "2007-02-03")
# Start the png device
png(filename="plot1.png", height=480, width=480, bg="transparent")
# creates plot1.png with a width of 480 pixels and a height of 480 pixels
# Plot the histogram
hist(sub_data$Global_active_power,
col="red",
main="Global Active Power",
xlab="Global Active Power (kilowatts)",
ylab="Frequency")
# Save the figure
dev.off()
# Plot 2
# Uses data from the UC Irvine Machine Learning Repository found at http://archive.ics.uci.edu/ml/
# Only data from 2007-02-01 and 2007-02-02 is used for the analysis
data <- read.table(file = "household_power_consumption.txt", sep = ";", skip = 66637,nrows = 2880,na.strings= "?")
dt <-  colnames(read.table("household_power_consumption.txt", sep = ";",nrow = 1, header = TRUE))
# Assigns column names
names(data) <- dt
str(data)
date_time <- paste(data$Date,data$Time)
day_week <- strptime(date_time, format ='%d/%m/%Y %H:%M:%S')
str(day_week)
# Start the png device
png("plot2.png",width =480,height=480)
# Creates plot2.png with a width of 480 pixels and a height of 480 pixels
plot(day_week,data$Global_active_power,type="l",xlab="",ylab="Global Active Power(kilowatts)")
# Saves figure
dev.off()
# Plot 2
# Uses data from the UC Irvine Machine Learning Repository found at http://archive.ics.uci.edu/ml/
# Only data from 2007-02-01 and 2007-02-02 is used for the analysis
data <- read.table(file = "household_power_consumption.txt", sep = ";", skip = 66637,nrows = 2880,na.strings= "?")
dt <-  colnames(read.table("household_power_consumption.txt", sep = ";",nrow = 1, header = TRUE))
# Assigns column names
names(data) <- dt
str(data)
date_time <- paste(data$Date,data$Time)
day_week <- strptime(date_time, format ='%d/%m/%Y %H:%M:%S')
str(day_week)
# Start the png device
png("plot2.png",width =480,height=480)
# Creates plot2.png with a width of 480 pixels and a height of 480 pixels
plot(day_week,data$Global_active_power,type="l",xlab="",ylab="Global Active Power(kilowatts)")
# Saves figure
dev.off()
# Plot 2
# Uses data from the UC Irvine Machine Learning Repository found at http://archive.ics.uci.edu/ml/
# Only data from 2007-02-01 and 2007-02-02 is used for the analysis
data <- read.table(file = "household_power_consumption.txt", sep = ";", skip = 66637,nrows = 2880,na.strings= "?")
dt <-  colnames(read.table("household_power_consumption.txt", sep = ";",nrow = 1, header = TRUE))
# Assigns column names
names(data) <- dt
str(data)
date_time <- paste(data$Date,data$Time)
day_week <- strptime(date_time, format ='%d/%m/%Y %H:%M:%S')
str(day_week)
# Start the png device
png("plot2.png",width =480,height=480)
# Creates plot2.png with a width of 480 pixels and a height of 480 pixels
plot(day_week,data$Global_active_power,type="l",xlab="",ylab="Global Active Power(kilowatts)")
# Saves figure
dev.off()
# Plot 1
# Uses data from the UC Irvine Machine Learning Repository found at http://archive.ics.uci.edu/ml/
# Only data from 2007-02-01 and 2007-02-02 is used for the analysis
data <- read.table(file = "household_power_consumption.txt", sep = ";", skip = 66637,nrows = 2880,na.strings= "?")
dt <-  colnames(read.table("household_power_consumption.txt", sep = ";",nrow = 1, header = TRUE))
# Assigns column names
names(data) <- dt
str(data)
date_time <- paste(data$Date,data$Time)
day_week <- strptime(date_time, format ='%d/%m/%Y %H:%M:%S')
str(day_week)
# Start the png device
png("plot1.png",width =480,height=480)
# Creates plot1.png with a width of 480 pixels and a height of 480 pixels
hist(data$Global_active_power,col="red", main ="Global Active Power",xlab="Global Active Power (kilowatts)")
# Saves figure
dev.off()
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
head(BodyWeight)
setwd("~/Desktop/Coursera/Cleansing Data/Course Project/Run_Analysis")
# Prepares a tidy data that can be used for later analysis
# Data for the project: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip
# Performs the following:
#1. Merges the training and the test sets to create one data set.
#2. Extracts only the measurements on the mean and standard deviation for each measurement.
#3. Uses descriptive activity names to name the activities in the data set
#4. Appropriately labels the data set with descriptive variable names.
#5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
# Installs required packages
if (!require("data.table")) {
install.packages("data.table")
}
require("data.table")
library(data.table)
# Downloads the file
# method="curl" relevant to MAC OSX
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl, destfile = "Dataset.zip", method="curl")
# Unzips file
unzip("Dataset.zip")
#1. Merges the training and the test sets to create one data set.
x_train <- read.table("./UCI HAR Dataset/train/X_train.txt", header = FALSE)
x_test <- read.table("./UCI HAR Dataset/test/X_test.txt", header = FALSE)
y_train <- read.table("./UCI HAR Dataset/train/y_train.txt", header = FALSE)
y_test <- read.table("./UCI HAR Dataset/test/y_test.txt", header = FALSE)
subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt", header = FALSE)
subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt", header = FALSE)
# Combines data tables
x_data <- rbind(x_train, x_test)
y_data <- rbind(y_train, y_test)
subject_data <- rbind(subject_train, subject_test)
#2. Extracts only the measurements on the mean and standard deviation for each measurement.
features <- read.table("./UCI HAR Dataset/features.txt")
# Provides descriptive variable names for features
names(features) <- c('feat_id', 'feat_name')
# Extracts the measurements on the mean and standard deviation
index_features <- grep("-mean\\(\\)|-std\\(\\)", features$feat_name)
x_data <- x_data[, index_features]
names(x_data) <- gsub("\\(|\\)", "", (features[index_features, 2]))
#3. Uses descriptive activity names to name the activities in the data set.
activities <- read.table("./UCI HAR Dataset/activity_labels.txt")
# Provides descriptive variable names for the activities
names(activities) <- c('act_id', 'act_name')
y_data[, 1] = activities[y_data[, 1], 2]
#4. Appropriately labels the data set with descriptive variable names.
names(y_data) <- "Activity"
names(subject_data) <- "Subject"
# creates a combined data table
tidy <- cbind(subject_data, y_data, x_data)
#5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
write.table(tidy,file="tidy.csv",sep=",",row.names = FALSE)
print("Finished processing. Tidy dataset has been written to tidy.csv")
